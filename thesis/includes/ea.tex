\chapter{Evolutionäre Algorithmen}
Im Jahre 1859 veröffentlichte Darwin sein Hauptwerk "`On the Origin of Species"' ("`Über die Entstehung der Arten"') \cite{Darwin:1}, in welchem er die Beobachtung formuliert, dass sich alle Lebewesen in langen Zeiträumen verändern und ihrer Umgebung anpassen. Dieser Prozess basiert laut Darwins These auf den Prozessen der \textit{natürlichen Selektion}. Ernst Mayr fasste Darwins Evolutionstheorie folgendermaßen zusammen \cite{Mayr:1}: 

\begin{enumerate}
	\item Jede Art bringt so viele Nachkommen vor, dass die Population wachsen würde, wenn alle Nachkommen überlebten.
	\item Die Populationsgröße einer Spezies ist langfristig konstant. 
	\item Ressourcen, die die Art für das Überleben benötigt, stehen nur begrenzt, aber über die Zeit in gleichbleibenden Mengen zur Verfügung. 
	\item Daraus folgt ein Kampf ums Überleben. 
	\item Die Individuen einer Population unterscheiden sich deutlich voneinander. 
	\item Die Unterschiede zwischen den Individuen beeinflussen ihre Fähigkeit in ihrer Umwelt zu überleben. 
	\item Individuen, die weniger gut an ihre Umwelt angepasst sind, haben eine geringere Überlebenschance und weniger Nachkommen. Individuen, die besser an ihre Umwelt angepasst sind, haben eine höhere Überlebenschance und mehr Nachkommen.
	\item Die Eigenschaften der Individuen mit einer höheren Überlebenschance verbreiten sich in der Population. Die Eigenschaften der Individuen mit einer geringeren Überlebenschance werden seltener vererbt und fallen damit aus der Population heraus. Dieser Prozess nennt sich natürliche Selektion. Dieser langsam voranschreitende Vorgang führt dazu, dass sich Populationen von Lebewesen sich über lange Zeitabschnitte an die Umwelt anpassen. 
\end{enumerate}

Im folgenden wird Darwins Evolutionstheorie anhand eines Beispiels aus \cite{Rabbits:1} erläutert. Es existiere eine Population von Hasen. Die einzelnen Hasen der Population haben unterschiedliche Eigenschaften: Einige sind schnell, andere sind langsam, manche sind schlau oder dumm. Diese Eigenschaften beeinflussen ihre Fähigkeiten, vor Füchsen (Man nehme an, dass diese auch existieren) zu fliehen. Dumme und langsame Hasen werden zu einer leichten Beute für Füchsen. Schnelle oder schlaue Hasen sind hingegen oft in der Lage, Füchsen zu entkommen, sei es, weil sie entweder schneller sind oder im richtigen Moment einen Haken schlagen, der ihnen einen großen Vorsprung verleiht. Da sie länger überleben oder (im falle des schlauen Hasen) besser Gefahr abschätzen können, sind sie öfter in der Lage, sich mit anderen Hasen zu paaren. Dumme Hasen merken hingegen unter Umständen nicht, dass ein Fuchs auf sie lauert und langsame Hasen entkommen dem Fuchs nicht. Jedoch können auch einige von ihnen überleben, sei es durch Glück. 

Der Teil der Population, der überlebt hat, pflanzt sich nun fort. Dabei entsteht eine gute Mischung an Jungen: Langsame Hasen paaren sich mit schlauen Hasen, schnelle Hasen mit schnellen Hasen, dumme Hasen mit schnellen Hasen, und so weiter. Bei manchen Jungen werden die Eigenschaften, die durch Kombination der Eigenschaften der Eltern entstanden sind, noch mutiert, wodurch ein besonders schlauer, dummer oder schneller Hase erzeugt wird. Die erzeugten Hasenjungen werden durchschnittlich schneller und schlauer sein als die der ursprünglichen Population, da mehr der schlauen und schnellen Hasen der Elterngeneration überlebt haben und sich paaren konnten. Nach einigen Generationen wird dieser Effekt deutlich: Die gesamte Population der Hasen ist schneller und schlauer als die Hasen der ersten Generation. (Man könnte sich nun Sorgen um die Füchse machen, da die meisten Jagdversuche unerfolgreich sind. Jedoch untergehen Sie den gleichen Evolutionsprozess wie die Hasen und werden ebenfalls schneller und schlauer.)

Evolutionäre Algorithmen (\acs{EA}) kopieren das Verfahren der natürlichen Evolution, wobei das Verfahren stark vereinfacht wird. Im Gegenteil zu natürlicher Evolution verfolgen EA jedoch ein spezifisches \textit{Ziel}. Das Ziel ist meistens ein zu lösendes Problem. Der EA erzeugt dafür eine \textit{Population} von Lösungskandidaten. Jeder dieser Kandidaten oder \textit{Individuen} enthält die nötige Information um ihren Lösungsversuch für das Problem zu repräsentieren. Diese Information wird in den meisten Fällen Kodiert in \textit{Genen} gespeichert. Mit einer vom Benutzer erstellen \textit{Fitness-Funktion} kann für jedes Individuum der \textit{Fitness-Wert} - die Qualität des Individuums für das gegebene Problem - bestimmt werden. Für den Paarungsprozess werden zunächst \textit{Eltern} ausgewählt, die in den Paarungs-Pool aufgenommen werden (dieser Schritt nennt sich \textit{Eltern-Selektion}). Aus dem Paarungs-Pool werden zwei Eltern ausgewählt, um \textit{rekombiniert} zu werden. Bei der \textit{Rekombination} wird ein Kind-Individuum erzeugt, das auch einen Lösungskandidat für das Problem repräsentiert. Die Kinder-Individuen stellen die Individuen der \textit{nächsten Generation} dar. Einige Individuen der neuen Generation werden zufällig ausgewählt, um \textit{mutiert} zu werden. In diesem Schritt werden einige Gene des Individuums zufällig geändert, um eine zusätzliche Vielfalt in der Population zu erreichen. Die meisten evolutionären Algorithmen arbeiten mit einer \textit{festen Populationsgröße}. Daher werden im Schritt der \textit{Umwelt-Selektion} die Individuen mit den besten Fitness-Werten aus der Eltern- und der Kind-Generation ausgewählt. Alle anderen Individuen werden entfernt. 

Mit der Zeit haben sich verschiedene Methoden für die Implementierung eines EA entwickelt, um bestimmte Probleme besser lösen zu können. Nur die generelle Struktur des Algorithmus ist meistens die gleiche. % TODO siehe Abbildung 

Im folgenden werden die Terminologie von evolutionären Algorithmen sowie die verschiedenen Verfahren in den Abschnitten von EA vorgestellt. 

\section{Terminologie}
% TODO
% Problem: P
% Fitnessfunktion: f: Ω -> R
% Suchraum des Problems: Ω
% Kodierter Suchraum: X
TODO

\section{Kodierung}
Um ein Optimierungsproblem mit einem \acs{EA} zu lösen, wird meist eine Übersetzung des Suchraums des Problems benötigt. Diese Übersetzung gleicht dem Genotyp-Phaenotyp-Modell aus der Genetik. Der Wert, der im Individuum gespeichert wird, ist der Genotyp. Damit lässt sich mit Hilfe der Kodierung der Phaenotyp berechnen. Der Phaenotyp stellt einen Lösungskandidaten für das Optimierungsproblem bzw. einen Wert aus dem Suchraum des Optimierungsproblem dar. Es muss also ein Alphabet erstellt werden, das durch den Kodierungsprozess einen Wert im Suchraum des Optimierungsproblems darstellt. 

In den frühen zeiten der evolutionären Algorithmen wurde die Genetik der Natur so weit berücksichtigt, dass man

Bei der Wahl der Kodierung sollten einige Grundregeln beachtet werden. Eine davon ist das \textit{Prinzip des minimalen Alphabets} von Goldberg \cite{Golderg:1}: 

\begin{quote}
Der Nutzer sollte das kleinstmögliche Alphabet nutzen, das dem natürlichen Ausdruck des Problems entgegenkommt.
\end{quote}

Es soll also weder ein zu großes, noch ein zu kleines Alphabet verwendet werden. Implmentiert der Nutzer ein zu großes Alphabet, so kann viel Rechenzeit beim Durchforsten zu kleiner und unwichtiger Teilbereiche des Alphabets verloren werden. Ist das Alphabet hingegen zu klein, so kann es sein, dass das Alphabet bestimmte Bereiche des Problems nicht abdeckt. Das ist insbesondere dann für den EA hinderlich, wenn das zu findende Optimum nicht durch das Alphabet dargestellt werden kann. 

Ein weiteres Kriterium für die gute Wahl einer Kodierung ist, dass die Entwicklung von Lösungen möglichst natürlich durch das Alphabet unterstützt wird. Damit wird erreicht, dass nah aneinander liegende Lösungen im Problem auch in ihrer kodierten Form im Individuum Ähnlichkeiten aufweisen. Auch kann dadurch der Rechenaufwand der Kodierung klein gehalten werden. 

\subsection{Binäre Kodierung}
\label{subsec:binary_coding}
In den Anfängen von \acs{EA} wurden fast ausschließlich binäre Kodierungen verwendet \cite{Gerdes:1}. 
Bei der binären Kodierung wird der Lösungsraum des Problems durch einen binären String $b = \mathbb{B}^k = {0, 1}^k$ repräsentiert. Mit mehr oder weniger Aufwand kann jedes Problem mit einer binären Kodierung repräsentiert werden. 

Im folgenden wird beispielhaft ein Problem vorgestellt, das sich sehr leicht mit binärer Kodierung repräsentieren lässt. Man nehme an, man hat einen Raum mit $n$ Lampen $L = \left\{l_1, l_2, \cdots , l_{n-1}, l_n\right\}$ und $n$ Schaltern $S = \left\{s_1, s_2, \cdots , s_{n-1}, s_n\right\}$. Jeder Schalter $s_i$ kann an oder aus sein und bedient damit, ob die Lampe $l_i$ an oder aus ist. Ziel ist, die Helligkeit an einer bestimmten Stelle des Raumes durch das An- und Ausschalten der Schalter auf einen gegebenen Wert zu optimieren. Für die Repräsentation des Problems lässt sich offensichtlich eine binäre Kodierung verwenden: Man nehme einen binären String der Länge $n$. Die $i$-te 0 (oder 1) stellt dar, dass der Schalter $s_i$ an (oder aus) ist. 

Eine weitere Verwendung der binären Kodierung ist die Darstellung vorzeichenloser Integer-Werte. In \ref{eq:binary_to_uint} wird dargestellt, wie die Kodierung eines vorzeichenlosen Integers $x$ mit einer Länge von $l$ Bit in einen binären String $A$ erfolgen kann. Werden für das Problem Integer-Werte mit Vorzeichen benötigt, so kann ein weiteres Bit als Vorzeichenbit verwendet werden. 

\begin{gather}
A = A_1 A_2 \dots A_{n-1} A_n \in \mathbb{B} \nonumber \\
\label{eq:binary_to_uint}
x = \sum\limits_{i=1}^n A_i \cdot 2^{n-i}
\end{gather}

Für viele Probleme werden mehrere Parameter benötigt. Damit eine Folge von Parametern binär kodiert werden kann, muss für jeden Parameter eine feste Länge bekannt sein. Liegt dies vor, können die einzelnen kodierten Werte im binären String aneinandergereiht werden. \ref{eq:multiple_uints} zeigt auf, wie die Kodierung von $m$ vorzeichenlosen Integer-Werten mit je $n$ Bit erfolgen kann. 

\begin{gather}
A = A_1 A_2 \dots A_{m \cdot n-1} A_{m \cdot n} \in \mathbb{B} \nonumber \\
\label{eq:multiple_uints}
x_k = \sum\limits_{i=1}^n A_{n(k-1)+i} \cdot 2^{n-i}
\end{gather}

Werden die Schalter im Beispiel oben durch Dimmer mit $k$ Stufen ausgetauscht, so lässt sich die in \ref{eq:multiple_uints} dargestellte Kodierung verwenden. $m$ ist dabei die Anzahl der Dimmer bzw. Lampen. Die Länge -- also die Anzahl der Bits -- der einzelnen vorzeichenlosen Integerwerte $n$ muss so gewählt werden, dass alle Dimmerstufen $k$ dargestellt werden können ($k \le 2^n$). 

% TODO relle Zahlen?
%Man nehme an, dass die Schalter im Beispiel durch stufenlose Dimmer ausgetauscht werden. Die Dimmer können nun also jeden reellen Zahlenwert zwischen 0 -- zugehörige Lampe ist aus -- und 1 -- zugehörige Lampe leuchtet mit maximaler Helligkeit -- annehmen. Hier wird man allerdings vor ein Problem gestellt: Es gibt unendlich viele reelle Zahlen zwischen 0 und 1. Um die reelle Zahl also exakt binär zu kodieren, muss die binäre Zahl unendlich viele Stellen haben. Dies ist mit einem Computer nicht möglich: Es gibt keinen Computer mit einem Speicher, der unendlich Bits aufnehmen kann. Stattdessen 

\subsection{Kodierung mit Fließkommazahlen}
Man nehme an, die Schalter aus dem Beispiel im Abschnitt \ref{subsec:binary_coding} werden durch stufenlose Dimmer ausgetauscht. Die Dimmer können also jeden reellen Zahlenwert zwischen 0 -- zugehörige Lampe ist aus -- und 1 -- zugehörige Lampe leuchtet mit maximaler Helligkeit -- annehmen. 
Werden die Schalter aus dem Beispiel \ref{subsec:binary_coding} durch stufenlose Dimmer ausgetauscht, 

\section{Fitnessfunktion}
Die Fitnessfunktion oder Zielfunktion bestimmt, wie "`fit"' bzw. wie gut ein Individuum ist und beeinflusst damit direkt die Überlebens- und Fortpflanzungschancen der Individuen. Es handelt sich dabei um  eine Abbildung, die jedem Element des Suchraums des Problems eine reelle Zahl als Bewertung zuweist. Dabei kann selbst entschieden werden, ob das fitteste Individuum den größten oder den kleinsten Fitnesswert haben soll, also, ob der Wert der Fitnessfunktion maximiert oder minimiert werden soll. Für Selektionsverfahren, die die Selektionswahrscheinlichkeit anhand der Fitness der Individuen bestimmen, stellen negative Fitnesswerte ein Problem dar, da auch die Selektionswahrscheinlichkeit negativ wird. Daher ist es üblich, die Fitnessfunktion so zu konstruieren, dass sie auf alle positive reelle Zahlen abbildet:

\begin{equation}
f: \Omega \to \mathbb{R}^+
\end{equation}

Die Fitness eines Individuums ist meistens relativ. Das bedeutet, die Fitness einzelnen Individuums sagt nichts über seine tatsächliche Qualität aus. Mit der Fitness lassen sich lediglich die Individuen unter sich vergleichen. 

% Keep?
% Man betrachte folgendes Beispiel: Es soll die Nullstelle der Funktion $g: \mathbb{R}^n \to \mathbb{R}$ durch einen EA bestimmt werden. Dies lässt sich einfach in ein Minimierungsproblem umwandeln, sodass das Individuum, das am nächsten an einer Nullstelle ist, den kleinsten Fitness-Wert hat. Dafür muss die gegebene Funktion $g$ in der Fitness-Funktion quadriert werden. 

% \begin{equation}
% \label{eq:fitness_example_1}
% f(\mathbf{x}) = g(\mathbf{x})^2, x \in \mathbb{R}^n
% \end{equation}

% Dadurch bewegt sich der Wertebereich von $f$ in $\mathbb{R}_0^+$. Das bedeutet, der kleinste Wert, das globale Minimum von $f$ kann nicht kleiner als $0$ sein. Dieser Wert von $f$ wird genau an der Stelle erreicht, an der $g$ eine Nullstelle hat. Bei einer Suche nach dem globalen Minimum von $f$ wird also nach den Nullstellen von $g$ gesucht.

% Mit der Fitnessfunktion lassen sich viele Probleme beschreiben. Beispielsweise ist es auch möglich, die Nullstelle einer Funktion zu suchen. 

% Der EA ist nur in der Lage, das globale Minimum oder Maximum einer Funktion zu suchen. Um das gegebene Problem P also zu optimieren, muss eine Funktion definiert werden, die das Problem in ein Minimierungs- oder Maximierungsproblem 
% Die Fitnessfunktion oder Zielfunktion bestimmt wie "`fit"' bzw. wie gut ein Individuum ist und beeinflusst damit direkt die Überlebens- und Fortpflanzungschancen der Individuen. Die Fitness eines Individuums wird dabei meist als reelle Zahl angegeben. 

% Die Fitnessfunktion wird dabei so gewählt, dass das zu optimierende Problem in ein Minimierungs- oder Maximierungsproblem umgewandelt wird. Die Mechanismen des EA sind nur in der Lage, das globale Minimum oder das globale Maximum der Fitnessfunktion zu finden. Die Fitnessfunktion ist also die einzige Verbindung des Algorithmus zu dem Problem. 

\section{Selektion}
Ähnlich wie in der Natur werden die unangepassten, unfitten Individuen aussortiert, sodass sie sich nicht mehr fortpflanzen können, während die angepassten, fitten Individuen ihre Gene besonders Gut an die nächste Generation der Population weitergeben können. Bei evolutionären Algorithmen begrenzt man sich auf zwei Punkte für jede neue Generation, in denen eine Selekiton simuliert wird. 
Die \textit{Eltern-Selektion} wählt die Individuen aus, die sich paaren sollen, um die nächste Generation an Individuen zu produzieren. Die \textit{Umwelt-Selektion} wählt nach der Paarung die überlebenden Individuen aus. 

% Keep?
% Weiterhin untscheidet man zwischen \textit{deterministischer} und \texit{probabilistischer} Selektion. Das Resultat einer \textit{deterministischen} Selektion ist dabei immer im Vorhinein bestimmbar; Eine \textit{probabilistische} Selektion hingegen wählt die Individuen mit zufälligen Entscheidungen aus und ist damit nicht im Vorhinein bestimmbar. Die \textit{probabilistische} Selektion ist hierbei an die natürliche Selektion angelehnt: Genauso wie im Beispiel am Anfang des Kapitels auch ein dummer oder langsamer Hase unter bestimmten Umständen dem Fuchs entwischen kann, ist es bei der non-deterministischen Selektion möglich, dass ein Individuum trotz seiner schlechteren Fitness überlebt. 

% Bei einigen Selektionsverfahren kann es passieren, dass ein Individuum dupliziert wird. Hier wird das in der Natur auftretende Szenario eines Individuums, das sich mehr als ein Mal paart, dargestellt. Diese Selektionsverfahren sind also speziell für die Eltern-Selektion vorgesehen. Die duplikative Auswahl der besseren Individuen bedeutet, dass sie ihre Gene besser verbreiten können als die Individuen die nur ein Mal oder gar nicht ausgewählt werden. Da die Umweltselektion direkt beeinflusst, welches Individuum für die nächste Generation behalten und welches aussortiert wird, eignet sich dieses Verfahren nicht für die Umwelt-Selektion. Meist ist die Populationsgröße fest definiert. Je mehr Duplikate eines Individuums in der Population existieren, desto höher ist die Wahrscheinlichkeit, dass sich zwei Duplikate paaren. Da diese beiden Individuum identische Gene haben, hat auch ihr Kind die identischen Gene. Handelt es sich bei den Duplikaten um ein besonders fittes Individuum, so kann es nach einigen Generationen dazu kommen, dass alle Individuen der Population die gleichen Gene haben. Ab diesem Punkt kann sich der Algorithmus nicht weiterentwickeln, da sich bei jedem Paarungsprozess zwei Individuen mit den gleichen Genen finden und ein Kind mit den gleichen Genen und der gleichen Fitness erzeugt, wie alle anderen. Es ist also höchstens durch die Mutation noch möglich, ein Individuum mit einer besseren Fitness zu finden, aber die Wahrscheinlichkeit dafür ist sehr gering. 

% TODO überleitender Abschnitt

\subsection{Varianten der Umwelt-Selektion}
Die Umwelt-Selektion wird durchgeführt, nachdem aus der Elterngeneration mit $\mu$ Eltern die Kindergeneration mit $\lambda$ Kindern erzeugt worden ist. Wichtig dabei ist, dass das Selektionsverfahren \textit{duplikatfrei} ist, also dass ein Individuum sich im Prozess der Selektion nicht vermehrfacht. Ein Duplikat vermindert die Diversität der Population. Ziel eines \acs{EA} ist, den Suchraum des Problems möglichst flächendeckend nach dem globalen Optimum abzusuchen. Um dies zu erreichen, benötigt es allerdings eine hohe Diversität. Im folgenden werden einige ausgewählte Verfahren für die Umwelt-Selektion vorgestellt. 

\paragraph{Plus-Selektion}
Die \textit{Plus-Selektion} oder auch $(\mu + \lambda)$\textit{-Selektion} ist ein deterministisches Selektionsverfahren. Bei diesem Verfahren werden aus beiden Generationen, der Eltern- und der Kindergeneration, die besten Individuen ausgewählt. Alle anderen Individuen werden gelöscht. 

\paragraph{Komma-Selektion}
Die \textit{Komma-Selektion} oder auch $(\mu, \lambda)$\textit{-Selektion} ist ebenfalls ein deterministisches Selektionsverfahren. Der Unterschied zwischen diesen beiden Verfahren ist, dass die Komma-Selektion nur Individuen aus der Kindergeneration auswählt. Damit die Population eine gleichbleibende Größe $popsize$ haben kann, müssen für dieses Selektionsverfahren bei einer Anzahl von $\mu$ Eltern-Individuen mindestens $\lambda \ge \mu$ Kinder-Individuen erzeugt worden sein. 

\paragraph{Q-stufige zweifache Turnierselektion}
Bei diesem Selektionsverfahren bestreitet jedes Individuum einen Wettkampf gegen $Q$ andere, zufällig ausgewählte Individuen $J = {j_1, \cdots, j_Q}$. Hat das Individuum $i$ eine bessere Fitness als das andere Individuum, so erhält es einen Punkt. Abschließend werden die Individuen, die in dem Wettkampf am meisten Punkte erzielt haben, selektiert. Dieses Verfahren ist \textit{probabilistisch}, was bedeutet, dass nicht garantiert werden kann, ob ein bestimmtes Individuum ausgewählt oder nicht ausgewählt wird. Diese Selektion kann entweder wie die Plus-Selektion sowohl auf die Eltern- als auch die Kinder-Generation oder wie die Komma-Selektion nur auf die Kinder-Generation angewandt werden. 

\subsection{Varianten der Eltern-Selektion}
In der Natur ist es üblich, dass sich die besser an die Umwelt angepassten Individuen öfter paaren, als die weniger angepassten Individuen. Dies kann unter anderem an ihrem Aussehen, ihrer Fertilität oder an ihrer Lebenslänge liegen. Gleichermaßen kann bei \acs{EA} anhand der Fitness entschieden werden, welches Individuum sich öfter und welches sich nicht reproduzieren darf. Dabei gilt: Jedes Mal, wenn ein Individuum selektiert wird, darf es sich mit einem anderen Indivduum paaren. Damit ein besonders fittes Individuum sich auch mehrere Male reproduzieren darf, muss die Erzeugung von Duplikaten bei der Eltern-Selektion gestattet sein. Im folgenden werden zwei ausgewählte Verfahren für die Eltern-Selektion vorgestellt. 

\paragraph{Roulette-Selektion}
Die \textit{Roulette-Selektion} (auch \textit{fitnessproportionale Selektion}) ist eine probabilistische Selektionsmethode. Es wird zunächst nach folgender Formel die Selektionswahrscheinlichkeit $P(I_k)$ jedes Individuums bestimmt: 
\begin{equation}
P(I_k) = \frac{f(I_k)}{\sum\limits_{j=1}^n f(I_j)},\;\;1 \le k \le n,
\end{equation}
wenn ein möglichst großer Fitness-Wert angestrebt wird, 
\begin{equation}
P(I_k) = \frac{f(I_k)^{-1}}{\sum\limits_{j=1}^n f(I_j)^{-1}},\;\;1 \le k \le n,
\end{equation}
wenn ein möglichst kleiner Fitness-Wert angestrebt wird, wobei $I$ die Menge aller zu selektierenden Individuen, $f(I_k)$ die Fitness des $k$-ten Individuums aus $I$ und $n$ die Anzahl der Individuen in $I$ ist. 
Die Individuen werden nun Fächern auf einem Roulette-Rad zugewiesen. Die Größe der Fächer ist dabei proportional zu der Selektionswahrscheinlichkeit des jeweiligen Individuums. Anschließend wird das Roulette-Rad gedreht und die Kugel eingeworfen. Das Individuum, in dessen Fach die Kugel fällt, wird selektiert. Dieser Prozess wird so oft wiederholt, bis die gewünschte Zahl an Individuen selektiert worden ist. 

\paragraph{Q-fache Turnierselektion}
Die \textit{Q-fache Turnierselektion} ist das Verfahren, auf dem die \textit{Q-stufige zweifache Turnierselektion} basiert. Das Individuum mit der besten Fitness gewinnt das Turnier und ist damit selektiert. Da Duplikate bei der Eltern-Selektion nicht verboten, sondern erwünscht sind, muss im Unterschied zur Q-stufigen zweifachen Turnierselektion keine Rangfolge für die Individuen bestimmt werden. Es werden so viele Turniere gespielt, wie Individuen selektiert werden sollen. 

\section{Rekombination}
Stub

\section{Mutation}
Stub

\section{Elitismus}
Stub

\section{Terminierungskriterien}
Stub






























